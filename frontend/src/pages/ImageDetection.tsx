import { useState, useEffect, useRef } from "react";
import * as mobilenet from "@tensorflow-models/mobilenet";
import * as tf from "@tensorflow/tfjs";
import styles from "./ImageDetection.module.css";

type Prediction = {
  className: string;
  probability: number;
};

const ImageDetection = () => {
  const [model, setModel] = useState<mobilenet.MobileNet | null>(null);
  const [currentImage, setCurrentImage] = useState<HTMLImageElement | null>(null);
  const [isScanning, setIsScanning] = useState(false);
  const [loading, setLoading] = useState("");
  const [predictions, setPredictions] = useState<Prediction[]>([]);
  const [showResults, setShowResults] = useState(false);
  const [showContent, setShowContent] = useState(false);
  const [imageSrc, setImageSrc] = useState<string>("");

  const originalImgRef = useRef<HTMLImageElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);
  const scanWindowRef = useRef<HTMLDivElement>(null);
  const scanLabelRef = useRef<HTMLDivElement>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);

  // Load model on mount
  useEffect(() => {
    loadModel();
  }, []);

  // Update image and canvas when content becomes visible
  useEffect(() => {
    if (showContent && imageSrc && currentImage) {
      console.log("üîÑ useEffect triggered - updating refs");
      
      // Wait for next tick to ensure DOM is rendered
      setTimeout(() => {
        if (originalImgRef.current) {
          originalImgRef.current.src = imageSrc;
          console.log("‚úÖ originalImgRef.current.src updated in useEffect");
        } else {
          console.log("‚ö†Ô∏è originalImgRef.current still null in useEffect");
        }
        
        if (canvasRef.current && currentImage) {
          drawGrid(currentImage);
          console.log("‚úÖ drawGrid called from useEffect");
        } else {
          console.log("‚ö†Ô∏è canvasRef.current or currentImage null in useEffect");
        }
      }, 50);
    }
  }, [showContent, imageSrc, currentImage]);

  const loadModel = async () => {
    setLoading("‚è≥ Chargement du mod√®le IA...");
    try {
      await tf.ready();
      const loadedModel = await mobilenet.load();
      setModel(loadedModel);
      setLoading("‚úÖ Mod√®le IA pr√™t ! Choisissez une image.");
    } catch (error) {
      console.error("Error loading model:", error);
      setLoading("‚ùå Erreur de chargement. Rechargez la page.");
    }
  };

  const handleFileSelect = (event: React.ChangeEvent<HTMLInputElement>) => {
    console.log("üîµ handleFileSelect called");
    const file = event.target.files?.[0];
    if (!file) {
      console.log("‚ùå No file selected");
      return;
    }

    console.log("‚úÖ File selected:", file.name, file.type, file.size);

    const reader = new FileReader();
    reader.onload = (e) => {
      console.log("üìñ FileReader onload triggered");
      const imgSrc = e.target?.result as string;
      console.log("üñºÔ∏è Image src set:", imgSrc.substring(0, 50) + "...");
      
      const img = new Image();
      img.src = imgSrc;
      
      img.onload = () => {
        console.log("‚úÖ Image loaded successfully!", img.width, "x", img.height);
        setCurrentImage(img);
        setImageSrc(imgSrc);
        console.log("‚úÖ setCurrentImage and setImageSrc called");
        
        setShowContent(true);
        console.log("‚úÖ setShowContent(true) called");
        setShowResults(false);
        console.log("‚úÖ setShowResults(false) called");
      };
      
      img.onerror = (error) => {
        console.error("‚ùå Image failed to load:", error);
      };
    };
    
    reader.onerror = (error) => {
      console.error("‚ùå FileReader error:", error);
    };
    
    reader.readAsDataURL(file);
    console.log("üìñ FileReader.readAsDataURL started");
  };

  const drawGrid = (img: HTMLImageElement) => {
    console.log("üé® drawGrid called with image:", img.width, "x", img.height);
    const canvas = canvasRef.current;
    if (!canvas) {
      console.log("‚ùå canvasRef.current is null");
      return;
    }
    console.log("‚úÖ Canvas ref found:", canvas);

    const ctx = canvas.getContext("2d");
    if (!ctx) {
      console.log("‚ùå Could not get 2d context");
      return;
    }
    console.log("‚úÖ Canvas context obtained");

    canvas.width = 400;
    canvas.height = 400;
    console.log("‚úÖ Canvas size set to 400x400");

    // Draw image
    ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
    console.log("‚úÖ Image drawn on canvas");

    // Draw grid
    const gridSize = 20;
    const cellWidth = canvas.width / gridSize;
    const cellHeight = canvas.height / gridSize;

    ctx.strokeStyle = "rgba(102, 126, 234, 0.3)";
    ctx.lineWidth = 1;

    // Vertical lines
    for (let i = 0; i <= gridSize; i++) {
      ctx.beginPath();
      ctx.moveTo(i * cellWidth, 0);
      ctx.lineTo(i * cellWidth, canvas.height);
      ctx.stroke();
    }

    // Horizontal lines
    for (let i = 0; i <= gridSize; i++) {
      ctx.beginPath();
      ctx.moveTo(0, i * cellHeight);
      ctx.lineTo(canvas.width, i * cellHeight);
      ctx.stroke();
    }
    console.log("‚úÖ Grid drawing completed");
  };

  const startScanning = async () => {
    if (isScanning || !currentImage) return;

    setIsScanning(true);
    setShowResults(false);

    // Afficher un message de chargement
    setLoading("üîç Analyse en cours...");

    // Attendre un peu pour l'effet visuel
    await new Promise((resolve) => setTimeout(resolve, 1000));

    setLoading("üß† Le cerveau de l'IA analyse l'image...");

    // Classifier l'image directement
    await classifyImage(currentImage);

    setIsScanning(false);
    setLoading("");
  };

  const classifyImage = async (img: HTMLImageElement) => {
    if (!model) {
      alert("Le mod√®le n'est pas encore charg√©. Attendez quelques secondes.");
      return;
    }

    setLoading("üß† Le cerveau de l'IA prend sa d√©cision...");

    try {
      const preds = await model.classify(img);
      setPredictions(preds);
      setShowResults(true);
      setLoading("");
    } catch (error) {
      console.error("Classification error:", error);
      setLoading("‚ùå Erreur d'analyse.");
    }
  };

  const isCat = () => {
    const catKeywords = ["tabby", "cat", "persian", "siamese", "egyptian", "tiger cat"];
    return predictions.some((pred) =>
      catKeywords.some((keyword) => pred.className.toLowerCase().includes(keyword))
    );
  };

  return (
    <div className={styles.container}>
      <h1 className={styles.title}>ü§ñ MiniMind ‚Äì Les Yeux Artificiels de l'IA</h1>
      <p className={styles.subtitle}>
        ¬´ Comment les yeux artificiels de l'IA d√©tectent-ils un chat ? ¬ª
      </p>

      <div className={styles.uploadSection}>
        <button
          className={styles.uploadBtn}
          onClick={() => fileInputRef.current?.click()}
        >
          üì∏ Choisir une image
        </button>
        <input
          ref={fileInputRef}
          type="file"
          accept="image/*"
          onChange={handleFileSelect}
          style={{ display: "none" }}
        />
      </div>

      {loading && <div className={styles.loading}>{loading}</div>}

      {showContent && (
        <div className={styles.contentGrid}>
          <div className={styles.panel}>
            <h2>üëÅÔ∏è Vision Humaine</h2>
            <img ref={originalImgRef} className={styles.image} alt="Original" />
            <p>
              C'est ce que <strong>vous</strong> voyez : une image compl√®te avec des
              formes, des couleurs et des textures.
            </p>
          </div>

          <div className={styles.panel}>
            <h2>ü§ñ Vision IA (D√©coup√©e)</h2>
            <div className={styles.scanContainer}>
              <canvas ref={canvasRef}></canvas>
              <div ref={scanWindowRef} className={`${styles.scanWindow} ${styles.hidden}`}></div>
              <div ref={scanLabelRef} className={`${styles.scanLabel} ${styles.hidden}`}>
                üîç Analyse...
              </div>
            </div>
            <button
              className={styles.analyzeBtn}
              onClick={startScanning}
              disabled={isScanning}
            >
              üîç Lancer l'analyse IA
            </button>
            <p>
              C'est ce que l'<strong>IA</strong> voit : l'image d√©coup√©e en petits morceaux
              (pixels) transform√©s en nombres.
            </p>
          </div>
        </div>
      )}

      {showResults && predictions.length > 0 && (
        <div className={styles.resultSection}>
          <div className={styles.resultBox}>
            <div
              className={styles.resultText}
              style={{ color: isCat() ? "#28a745" : "#dc3545" }}
            >
              {isCat()
                ? "üê± OUI ! L'IA a d√©tect√© un CHAT !"
                : "‚ùå NON, ce n'est pas un chat."}
            </div>
            <div className={styles.confidence}>
              L'IA pense que c'est :{" "}
              <strong>{predictions[0].className}</strong> (
              {(predictions[0].probability * 100).toFixed(1)}% de confiance)
            </div>

            <div className={styles.predictions}>
              <strong>üîç Top 3 des pr√©dictions de l'IA :</strong>
              {predictions.slice(0, 3).map((pred, index) => {
                const emoji = index === 0 ? "ü•á" : index === 1 ? "ü•à" : "ü•â";
                return (
                  <div key={index} className={styles.predictionItem}>
                    <span>
                      {emoji} {pred.className}
                    </span>
                    <span>
                      <strong>{(pred.probability * 100).toFixed(1)}%</strong>
                    </span>
                  </div>
                );
              })}
            </div>
          </div>

          <div className={styles.explanation}>
            <h3>üí° Comment √ßa marche ?</h3>
            <p>
              1. <strong>L'IA scanne l'image avec ses "yeux artificiels"</strong> (la
              fen√™tre verte 9x9)
            </p>
            <p>
              2. <strong>Chaque zone scann√©e est transform√©e en nombres</strong> (comme 1
              000 000 de chats m√©moris√©s)
            </p>
            <p>
              3. <strong>L'IA compare chaque morceau</strong> avec les 1 000 000 de chats
              qu'elle a vus pendant son entra√Ænement
            </p>
            <p>
              4. <strong>Le r√©seau de neurones reconna√Æt les formes</strong> : oreilles
              pointues, moustaches, yeux de chat...
            </p>
            <p>
              5. <strong>Elle donne son verdict final</strong> avec un pourcentage de
              confiance !
            </p>
            <p>
              <em>
                ‚ú® L'IA a appris en voyant 1 million d'images de chats et sait maintenant
                reconna√Ætre leurs caract√©ristiques !
              </em>
            </p>
          </div>
        </div>
      )}
    </div>
  );
};

export default ImageDetection;
